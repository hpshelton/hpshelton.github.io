---
layout: post
type: link
date: 2025-09-21 18:00:00 -0700
title: "ADD / XOR / ROL: A non-anthropomorphized view of LLMs"
link: https://addxorrol.blogspot.com/2025/07/a-non-anthropomorphized-view-of-llms.html
permalink: /post/2025/09/21/anthropomorphized-llms
categories: 
- artificial intelligence
- ai
- llm
- large language model
---
<blockquote>Instead of saying "we cannot ensure that no harmful sequences will be generated by our function, partially because we don't know how to specify and enumerate harmful sequences", we talk about "behaviors", "ethical constraints", and "harmful actions in pursuit of their goals". All of these are anthropocentric concepts that - in my mind - do not apply to functions or other mathematical objects. And using them muddles the discussion, and our thinking about what we're doing when we create, analyze, deploy and monitor LLMs.</blockquote>