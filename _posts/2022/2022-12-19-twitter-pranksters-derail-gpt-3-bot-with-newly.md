---
layout: post
type: link
date: 2022-12-19 02:30:31 GMT
title: "Twitter pranksters derail GPT-3 bot with newly discovered \"prompt injection\" hack"
link: https://arstechnica.com/information-technology/2022/09/twitter-pranksters-derail-gpt-3-bot-with-newly-discovered-prompt-injection-hack/
permalink: /post/704031785252749314/twitter-pranksters-derail-gpt-3-bot-with-newly
redirect_from: 
  - /post/704031785252749314/twitter-pranksters-derail-gpt-3-bot-with-newly
categories:
- bot
- ai
- artificial intelligence
---
<blockquote>On Thursday, a few Twitter users discovered how to hijack an automated tweet bot, dedicated to remote jobs, running on the GPT-3 language model by OpenAI. Using a newly discovered technique called a "prompt injection attack," they redirected the bot to repeat embarrassing and ridiculous phrases.</blockquote>
<p>Who could have known that this could be an issue? <a href="https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/">Oh, wait</a>.</p>